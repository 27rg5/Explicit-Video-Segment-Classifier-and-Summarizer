# -*- coding: utf-8 -*-
"""LDA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fM09p2DY-aDP1IYWcU5RwbR4jSKBkfkp

## Import packages
"""

import pandas as pd
from bertopic import BERTopic
from gensim.models import TfidfModel
import joblib
import shutil
from joblib import dump, load
from sklearn.model_selection import ParameterGrid
import json
import os
import numpy
import pyLDAvis
import pyLDAvis.gensim
import numpy as np
import pandas as pd
import re
import pdb
import time
import logging
import argparse
from multiprocessing import Pool
from joblib import Parallel, delayed
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split, GridSearchCV, PredefinedSplit,RandomizedSearchCV
from sklearn.metrics import accuracy_score, f1_score
from gensim.models.coherencemodel import CoherenceModel
import gensim
from gensim.utils import simple_preprocess
import plotly.graph_objects as go
import gensim.corpora as corpora
import warnings
from data_utils import caption_files_exist
from LDA import get_corpus_from_captions
np.random.seed(42)

# Suppress all warnings
warnings.filterwarnings('ignore')

def setup_logger(logger_name, model_topic_param_dir,  level=logging.INFO):
    log_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s : %(message)s')

    log_file = os.path.join(model_topic_param_dir, f'gridsearch_logs.log')
    handler = logging.FileHandler(log_file)
    handler.setFormatter(log_format)

    logger = logging.getLogger(logger_name)
    logger.setLevel(level)
    logger.addHandler(handler)

    return logger

def makedir(dir_):
    os.makedirs(dir_, exist_ok=True)

def get_captions_and_preds_from_experiement_dir(experiment_dir):
    train_caption_df = pd.read_csv(os.path.join(experiment_dir,'lda_preds_train.csv'))
    train_caption_df['Video path'] = train_caption_df['Video path'].apply(lambda x: x.strip("[]").strip("'"))
    val_caption_df = pd.read_csv(os.path.join(experiment_dir,'lda_preds.csv'))
    val_caption_df['Video path'] = val_caption_df['Video path'].apply(lambda x: x.strip("[]").strip("'"))
    train_caption_df['dataset_type'] = 'train'
    val_caption_df['dataset_type'] = 'val'
    train_preds_df = pd.read_csv(os.path.join(experiment_dir,'predictions_train.csv'))
    train_preds_df['Video path'] = train_preds_df['Video path'].apply(lambda x: x.strip("[]").strip("'"))
    train_preds_dict = dict(zip(train_preds_df['Video path'], train_preds_df['Target']))
    val_preds_df = pd.read_csv(os.path.join(experiment_dir,'predictions_test.csv'))
    val_preds_df['Video path'] = val_preds_df['Video path'].apply(lambda x: x.strip("[]").strip("'"))
    val_preds_dict = dict(zip(val_preds_df['Video path'], val_preds_df['Target']))
    return train_caption_df, val_caption_df, train_preds_dict, val_preds_dict

    
def prepare_data(train_caption_df, val_caption_df, lda_type='bertopic'):
    print('Preparing data for grid search...')
    captions_df = pd.concat([train_caption_df, val_caption_df], ignore_index=True)
    all_captions_dict = dict(zip(captions_df['Video path'].values, zip(captions_df['dataset_type'].values, captions_df['Caption'].values)))
    all_captions_dict = get_corpus_from_captions(all_captions_dict, lda_type)
    print('Done')
    return all_captions_dict, pd.DataFrame([{'Video path':k, 'dataset_type':v[0], 'Feature':v[1]} for k,v in all_captions_dict.items()])

#Grid search to find the best parameters
def grid_search(video_topic_feats_df, train_preds_dict, val_preds_dict, model_name, model_dir, logger_):
    #st_time = time.time()
    X_train = pd.DataFrame(columns=['topics'])
    y_train = pd.DataFrame(columns=['ans'])
    X_test = pd.DataFrame(columns=['topics'])
    y_test = pd.DataFrame(columns=['ans'])

    #pdb.set_trace()
    for i, row in video_topic_feats_df.iterrows():
        if row['dataset_type'] == 'train':
            X_train.at[i, 'topics'] = [row['Feature']]
            y_train.at[i, 'ans'] = 1 if train_preds_dict[row['Video path']]=='explicit' else 0
        else:
            X_test.at[i, 'topics'] = [row['Feature']]
            y_test.at[i, 'ans'] = 1 if val_preds_dict[row['Video path']]=='explicit' else 0
            
            
    parameter_space = {
            'hidden_layer_sizes': [(i, j) for i in range(10, 500, 10) for j in range(10, 500, 10)],
            'max_iter':[i for i in range(100, 5000, 100)],
            'solver':['sgd','adam','lbfgs'],
            'alpha':[0.0001, 0.001, 0.01, 0.1],
            'learning_rate':['constant', 'invscaling', 'adaptive'],
            'learning_rate_init': [1e-4, 1e-3, 1e-2, 1e-1],
            'activation':['identity', 'logistic', 'tanh', 'relu'],
            'nesterovs_momentum':[True, False]
            # 'early_stopping':[True, False],
            # 'n_iter_no_change':[i for i in range(100, 4000, 100)],
#            'tol': [1e-2, 1e-3, 1e-4, 1e-5]
        }    
    
    clf = MLPClassifier(random_state=42)
    X_train = [x[0] for x in X_train.topics.to_list()]
    X_test = [x[0] for x in X_test.topics.to_list()]
    y_train = y_train.ans.to_list()
    y_test = y_test.ans.to_list()
    num_topics = len(X_train[0])

    
    X_combined = X_train + X_test
    y_combined = y_train + y_test
    test_fold = np.array([-1 for i in range(len(X_train))] + [0 for i in range(len(X_test))])
    logger_.info(f'Training on {np.where(test_fold==-1)[0].shape[0]} samples and testing on {np.where(test_fold==0)[0].shape[0]} samples')
    logger_.info(f'Staring random search for model {model_name} with topics {num_topics}...')
    max_num_iterations = 4800
    grid = RandomizedSearchCV(clf, parameter_space, n_iter = max_num_iterations, cv=PredefinedSplit(test_fold), n_jobs=-1, scoring='f1', random_state = 42)
    grid.fit(X_combined, y_combined)

#    pdb.set_trace()
    best_model = grid.best_estimator_
    best_model_params = best_model.coefs_
    y_pred_test = best_model.predict(X_test)
    best_params = grid.best_params_
    test_accuracy = accuracy_score(y_test, y_pred_test)
    test_f1 = f1_score(y_test, y_pred_test)
    best_params.update({'test_f1':test_f1, 'test_accuracy':test_accuracy})

    logger_.info(f'For num topics {num_topics} and model {model_name}')
    logger_.info("Best parameters found: %s",best_params )
    logger_.info("Test Accuracy: %f", test_accuracy)
    logger_.info("Test F1 Score: %f", test_f1)

    model_path = os.path.join(model_dir, f'best_model_{model_name}_test_f1_{test_f1}.pkl')
    param_details_path = os.path.join(model_dir, f'best_params_{model_name}_test_f1_{test_f1}.json')
    model_params_path = os.path.join(model_dir, f'best_model_params_{model_name}_test_f1_{test_f1}')
    dump(best_model, model_path)
    dump(best_model_params, model_params_path)
    json.dump(best_params, open(param_details_path, 'w'))
    # time_taken_log = f'Time taken for model {model_name} with topics {num_topics} is {time.time()-st_time} seconds for {max_num_iterations} iterations \n\n'
    # print(time_taken_log)
    # logger_.info(time_taken_log)
    


if __name__=='__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--experiment_name',type=str)
    parser.add_argument('--root_dir',type=str)

    args = parser.parse_args()
    runs_dir = os.path.join(os.path.join(os.path.expanduser("~"), 'Explicit-Video-Segment-Classifier-and-Summarizer'),'runs')
    root_dir = args.root_dir
    experiment_name = args.experiment_name
    experiment_dir = os.path.join(runs_dir, experiment_name)
    print('Getting captions and predictions from experiment directory..')
    train_captions_csv, val_captions_csv, files_exist = caption_files_exist(root_dir)

    if files_exist:
        train_captions_df = pd.read_csv(train_captions_csv)
        val_captions_df = pd.read_csv(val_captions_csv)
        train_caption_df['dataset_type'] = 'train'
        val_caption_df['dataset_type'] = 'val'
        train_preds_df = pd.read_csv(os.path.join(experiment_dir,'predictions_train.csv'))
        val_preds_df = pd.read_csv(os.path.join(experiment_dir,'predictions_test.csv'))
    else:
        train_captions_df, val_captions_df, train_preds_dict, val_preds_dict = get_captions_and_preds_from_experiement_dir(experiment_dir)

    print('Done')
    gridsearch_root_dir = os.path.join(experiment_dir, 'lda_gridsearch_experiments')
    if os.path.exists(gridsearch_root_dir):
        shutil.rmtree(gridsearch_root_dir)

    makedir(gridsearch_root_dir)
    print('Starting grid search for all models...')
    for model_name in ['bertopic', 'tfidf_model']:
        print(f'Starting gridsearch for model {model_name}...')
        _, video_topic_feats_df = prepare_data(train_captions_df, val_captions_df, lda_type=model_name)
        model_dir = os.path.join(gridsearch_root_dir,f'{model_name}')
        makedir(model_dir)
        logger_ = setup_logger(f'{model_name}', model_dir)

        grid_search(video_topic_feats_df, train_preds_dict, val_preds_dict, model_name, model_dir, logger_)
        print('Done')